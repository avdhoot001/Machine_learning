{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPIFw67JAwNyLBpIC5/cRsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avdhoot001/Machine_learning/blob/main/rock_segment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "swKQGFABeG-q"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from typing import Literal\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image as Image\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm, trange\n",
        "from glob import glob\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "SvgqS5l6fdrO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://xeek-public-287031953319-eb80.s3.amazonaws.com/stranger-sections-2/stranger-sections-2-train-data.zip #training data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGtxgULDehGX",
        "outputId": "914c32f6-87f4-49fa-f0c6-f9e92ec27dab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-14 06:28:44--  https://xeek-public-287031953319-eb80.s3.amazonaws.com/stranger-sections-2/stranger-sections-2-train-data.zip\n",
            "Resolving xeek-public-287031953319-eb80.s3.amazonaws.com (xeek-public-287031953319-eb80.s3.amazonaws.com)... 54.231.225.233, 3.5.29.139, 3.5.27.31, ...\n",
            "Connecting to xeek-public-287031953319-eb80.s3.amazonaws.com (xeek-public-287031953319-eb80.s3.amazonaws.com)|54.231.225.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26029613 (25M) [application/zip]\n",
            "Saving to: ‘stranger-sections-2-train-data.zip’\n",
            "\n",
            "stranger-sections-2 100%[===================>]  24.82M  24.5MB/s    in 1.0s    \n",
            "\n",
            "2024-05-14 06:28:45 (24.5 MB/s) - ‘stranger-sections-2-train-data.zip’ saved [26029613/26029613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool\n",
        "import patoolib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrhMfGSnehIu",
        "outputId": "0b4013d1-0a6f-4f76-e7fe-1e1dc883c0a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-2.2.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patoolib.extract_archive('/content/stranger-sections-2-train-data.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "C20LjocXehK9",
        "outputId": "259c2ff0-e4cf-4fed-dae5-519d73127bb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting /content/stranger-sections-2-train-data.zip ...\n",
            "INFO:patool:Extracting /content/stranger-sections-2-train-data.zip ...\n",
            "INFO patool: running /usr/bin/7z x -o./Unpack_xtz92wzo -- /content/stranger-sections-2-train-data.zip\n",
            "INFO:patool:running /usr/bin/7z x -o./Unpack_xtz92wzo -- /content/stranger-sections-2-train-data.zip\n",
            "INFO patool:     with input=''\n",
            "INFO:patool:    with input=''\n",
            "INFO patool: ... /content/stranger-sections-2-train-data.zip extracted to `stranger-sections-2-train-data' (multiple files in root).\n",
            "INFO:patool:... /content/stranger-sections-2-train-data.zip extracted to `stranger-sections-2-train-data' (multiple files in root).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stranger-sections-2-train-data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://youtu.be/XyX5HNuv-xE\n",
        "# https://youtu.be/q-p8v1Bxvac\n",
        "\"\"\"\n",
        "Standard Unet\n",
        "Model not compiled here, instead will be done externally to make it\n",
        "easy to test various loss functions and optimizers.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    #Expansive path\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    return model\n",
        ""
      ],
      "metadata": {
        "id": "qNoLo2yCehM3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import normalize\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "k6my34ztehPN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing images, if needed\n",
        "SIZE_X = 256\n",
        "SIZE_Y = 256\n",
        "n_classes=4 #Number of classes for segmentation"
      ],
      "metadata": {
        "id": "ym1RAiSiehSE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images = sorted(glob.glob('/content/stranger-sections-2-train-data/image/*'))\n",
        "\n",
        "start_no = 0\n",
        "for image in tqdm(images):\n",
        "    # Load the large image\n",
        "    large_image = tf.keras.preprocessing.image.load_img(image)\n",
        "\n",
        "    # Convert the image to a tensor\n",
        "    large_image = tf.keras.preprocessing.image.img_to_array(large_image)\n",
        "    # Reshape the tensor to have a batch size of 1\n",
        "    large_image = tf.reshape(large_image, [1, *large_image.shape])\n",
        "    # Extract patches from the large image\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=large_image,\n",
        "        sizes=[1, 256, 256, 1],\n",
        "        strides=[1, 128, 128, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "    # Reshape the patches tensor to have a batch size of -1\n",
        "    patches = tf.reshape(patches, [-1, 256, 256, 3])\n",
        "\n",
        "\n",
        "    # Write patches to files\n",
        "    for i in range(patches.shape[0]):\n",
        "        im = np.asarray(patches[i,:,:,:]).astype('uint8')\n",
        "        imname = 'im%03d.png'%(start_no + i)\n",
        "\n",
        "        im = Image.fromarray(im.astype(np.uint8))\n",
        "        im.save(os.path.join(\"/content/image_patches\",imname))\n",
        "\n",
        "    start_no = start_no + patches.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EziwxOjXehkF",
        "outputId": "890f22c4-7892-4d38-ec2b-76edeaa8902d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 87/87 [03:21<00:00,  2.31s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = sorted(glob.glob('/content/stranger-sections-2-train-data/label/*'))\n",
        "start_no = 0\n",
        "for image2 in tqdm(labels):\n",
        "    array = np.load(image2)\n",
        "\n",
        "    # Load the large image\n",
        "    # large_image = tf.keras.preprocessing.image.load_img(image)\n",
        "    # large_image = image\n",
        "    # Convert the image to a tensor\n",
        "    # large_image = tf.keras.preprocessing.image.img_to_array(large_image)\n",
        "    large_image = tf.convert_to_tensor(array)\n",
        "\n",
        "# Check the type and shape of the tensor\n",
        "    # print(\"Type of the tensor:\", type(large_image))\n",
        "    # print(\"Shape of the tensor:\", large_image.shape)\n",
        "\n",
        "    large_image = large_image[:,:,np.newaxis] # only keep one layer and add a new axis\n",
        "    # Reshape the tensor to have a batch size of 1\n",
        "    large_image = tf.reshape(large_image, [1, *large_image.shape])\n",
        "    # Extract patches from the large image\n",
        "    patches = tf.image.extract_patches(\n",
        "        images=large_image,\n",
        "        sizes=[1, 256, 256, 1],\n",
        "        strides=[1, 128, 128, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "    # Reshape the patches tensor to have a batch size of -1\n",
        "    patches = tf.reshape(patches, [-1, 256, 256, 1])\n",
        "    # Write patches to files\n",
        "    for i in range(patches.shape[0]):\n",
        "        im = np.asarray(patches[i,:,:,0]).astype('uint8')\n",
        "        imname =  'im%03d.png'%(start_no + i)\n",
        "        im = Image.fromarray(im.astype(np.uint8))\n",
        "        im.save(os.path.join(\"/content/label_patches\",imname))\n",
        "\n",
        "    start_no = start_no + patches.shape[0]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLF6x2xcehlw",
        "outputId": "5912644d-921a-48a4-c6df-8d2872a95267"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 87/87 [00:15<00:00,  5.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"/content/label_patches/im000.png\")  # Replace \"your_image.jpg\" with the path to your JPG image\n",
        "image_array = np.array(image)\n",
        "image_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jum6fV5mehnT",
        "outputId": "a5e7ce80-b848-4fd5-8f28-af1244380662"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = []\n",
        "import glob\n",
        "for directory_path in glob.glob(\"/content/image_patches\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        img = cv2.imread(img_path, 0)\n",
        "        #img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "        train_images.append(img)\n",
        "\n",
        "#Convert list to array for machine learning processing\n",
        "train_images = np.array(train_images)"
      ],
      "metadata": {
        "id": "fCapPSEFehpU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYdsG1w-ehq-",
        "outputId": "5996034f-9a16-4376-82b8-8460111c33b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5481, 256, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks = []\n",
        "for directory_path in glob.glob(\"/content/label_patches\"):\n",
        "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        mask = cv2.imread(mask_path, 0)\n",
        "        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
        "        train_masks.append(mask)\n",
        "\n",
        "#Convert list to array for machine learning processing\n",
        "train_masks = np.array(train_masks)"
      ],
      "metadata": {
        "id": "-K7kzGEjehsx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-yyqheIehvk",
        "outputId": "a569f1b4-0af2-434b-f947-7e8f2cb0f944"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5481, 256, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "train_images = normalize(train_images, axis=1)"
      ],
      "metadata": {
        "id": "vyUpGxUAeh1C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks_input = np.expand_dims(train_masks, axis=3)"
      ],
      "metadata": {
        "id": "axyHg8f4pH0u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n"
      ],
      "metadata": {
        "id": "Ud4M9HwRpH3H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.9, random_state = 0)"
      ],
      "metadata": {
        "id": "2hdm7FK9wBDh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 4\n",
        "from keras.utils import to_categorical\n",
        "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
        "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
        "\n"
      ],
      "metadata": {
        "id": "G4MIqFrypH5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
        "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n",
        "\n"
      ],
      "metadata": {
        "id": "ryvK4BIlpH7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_masks_reshaped_encoded),\n",
        "                                                 train_masks_reshaped_encoded)\n",
        "print(\"Class weights are...:\", class_weights)\n"
      ],
      "metadata": {
        "id": "3ScEqPc8pH9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "WrvyYbO9pH-b",
        "outputId": "141b57b7-b08f-4cb1-f8b9-8226bc29f4f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f55fd50a8e1b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIMG_HEIGHT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mIMG_CHANNELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xQwgY03LpIBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X1, y_train_cat,\n",
        "                    batch_size = 16,\n",
        "                    verbose=1,\n",
        "                    epochs=20,\n",
        "                    validation_data=(X_test, y_test_cat),\n",
        "                    class_weight=class_weights,\n",
        "                    shuffle=False)\n",
        ""
      ],
      "metadata": {
        "id": "PNNq9ab5pINW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('test.hdf5')"
      ],
      "metadata": {
        "id": "UxJ1zKpSpIPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(X_test, y_test_cat)\n",
        "print(\"Accuracy is = \", (acc * 100.0), \"%\")\n"
      ],
      "metadata": {
        "id": "_PUqySDYpIR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LQmTMleSyL3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "43F1xPpZyL02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)"
      ],
      "metadata": {
        "id": "mNcygD4DyLyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWEGv1YHyLv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hO95cx-TyLtL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}